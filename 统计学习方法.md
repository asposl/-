# 统计学习方法

## 概论

### 研究对象

#### 基本假设

同类数据具有一定的统计规律性

- 同类数据是指具有某种共同性质的数据，如英文文章、互联网网页

#### 方法

1. 从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布的
2. 假设要学习的模型属于某个函数的集合，称为假设空间
3. 应用某个评价准则，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据在给定的评价准则下有最优的预测
4. 最优模型的选取由算法实现

### 分类

#### 基本分类

1. 监督学习：从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监督学习的本质是学习从输入到输出的映射的统计规律。

   1. 输入空间、特征空间和输出空间

   2. 联合概率分布

2. 无监督学习：从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无监督学习的本质是学习数据中的统计规律或潜在结构。

3. 强化学习：智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。

4. 半监督学习与主动学习

#### 按模型分类

1. 概率模型和非概率模型

   在监督学习中，概率模型是生成模型，非概率模型是判别模型。

   概率模型一定可以表示为联合概率分布的形式，其中的变量表示输入、输出、隐变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。

2. 线性模型与非线性模型

3. 参数化模型和非参数化模型

   参数化模型假设模型的参数维度固定，模型可以由有限维参数完全刻画；非参数模型假设模型参数的维度不固定或无穷大，随着训练数据量的增加而不断增加。

#### 按算法分类

在线学习和批量学习

#### 按技巧分类

1. 贝叶斯学习
2. 核方法

### 三要素

#### 模型

学习什么样的模型

#### 策略

损失函数度量一次预测的好坏，常用：

1. 0-1损失函数
2. 平方损失函数
3. 绝对损失函数
4. 对数损失函数或对数似然损失函数

风险函数度量平均意义下模型预测的好坏，是损失函数的期望，也称损失期望。由于期望风险最小模型要使用未知的联合分布，所以一般使用模型关于训练数据集的平均损失，即经验风险或经验损失来估计期望风险。

经验风险最小化（大数定律）和结构风险最小化（正则化）

#### 算法

对最优化问题的求解。

### 模型评估与模型选择

#### 训练误差和测试误差

### 正则化与交叉验证

正则化项一般是模型复杂度的单调递增函数。作用是选择经验风险和模型复杂度同时较小的模型。

- 奥卡姆剃刀原理
- 从贝叶斯估计的角度看，正则化项对于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。

在数据不充足时，为了选择好的模型，可以使用交叉验证方法。

- 简单交叉验证
- S折交叉验证
- 留一交叉验证

### 泛化能力

泛化误差（即期望风险）

- 分析泛化误差一般通过研究泛化误差上界。泛化误差上界通常具有以下性质：
  1. 它是样本容量的函数，当样本容量增加时，泛化上界趋于0；
  2. 是假设空间容量的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。

定理1.1 p46 

### 生成模型和判别模型

### 监督学习的应用

- 分类问题
- 标注问题
- 回归问题





## 感知器















































   

​		

   